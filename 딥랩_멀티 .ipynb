{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00416acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np \n",
    "from tensorflow.keras import layers\n",
    "from scipy.io import loadmat\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf \n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "from PIL import ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d3735be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_image2'\n",
    "target_dir = 'C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_mask4'\n",
    "img_size = (224,224)\n",
    "num_classes = 7\n",
    "batch_size = 16\n",
    "\n",
    "input_img_paths = sorted([os.path.join(input_dir,fname)\n",
    "                         for fname in os.listdir(input_dir)\n",
    "                         if fname.endswith('.jpg')])\n",
    "\n",
    "target_img_paths = sorted([os.path.join(target_dir,fname)\n",
    "                         for fname in os.listdir(target_dir)\n",
    "                         if fname.endswith('.png') and not fname.startswith('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f72bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB value to class label mapping\n",
    "RGB_TO_LABEL = {\n",
    "    '[0, 0, 0]': 0,  # Background class\n",
    "    '[255, 0, 0]': 1,\n",
    "    '[0, 0, 255]': 2,\n",
    "    '[0, 255, 0]': 3,\n",
    "    '[255, 255, 0]': 4,\n",
    "    '[128, 0, 128]': 5,\n",
    "    '[255, 165, 0]': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11b8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_img(path, target_size, rgb_to_label):\n",
    "    # Load image in RGB mode\n",
    "    img = load_img(path, target_size=target_size)\n",
    "    img_array = img_to_array(img).astype(int)  # Convert RGB values to integers\n",
    "    # Initialize an empty array to hold the labels\n",
    "    label_array = np.zeros(img_array.shape[:-1], dtype=np.uint8)\n",
    "    # Iterate over each pixel and replace RGB value with corresponding label\n",
    "    for i in range(label_array.shape[0]):\n",
    "        for j in range(label_array.shape[1]):\n",
    "            rgb = img_array[i, j, :3]\n",
    "            rgb_str = str(rgb.tolist())\n",
    "            if rgb_str in rgb_to_label:\n",
    "                label_array[i, j] = rgb_to_label[rgb_str]\n",
    "            else:\n",
    "                raise ValueError(f\"RGB value {rgb_str} not in RGB_TO_LABEL dictionary.\")\n",
    "    return label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3898e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDiseaseDataset(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i:i+self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i:i+self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype='float32')\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img_to_array(img) / 255.  # input normalization\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype='uint8')\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            label_array = load_mask_img(path, self.img_size, RGB_TO_LABEL)\n",
    "            y[j] = np.expand_dims(label_array, -1)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8324602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "val_samples = 600\n",
    "random.Random(1337).shuffle(input_img_paths)\n",
    "random.Random(1337).shuffle(target_img_paths)\n",
    "\n",
    "train_input_img_paths = input_img_paths[:-val_samples]\n",
    "train_target_img_paths = target_img_paths[:-val_samples]\n",
    "val_input_img_paths = input_img_paths[-val_samples:]\n",
    "val_target_img_paths = target_img_paths[-val_samples:]\n",
    "\n",
    "train_gen = SkinDiseaseDataset(batch_size, img_size, train_input_img_paths, train_target_img_paths)\n",
    "val_gen = SkinDiseaseDataset(batch_size, img_size, val_input_img_paths, val_target_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f696feb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 224, 224, 3) (16, 224, 224, 1)\n",
      "0.0 1.0 0 5\n"
     ]
    }
   ],
   "source": [
    "x, y = train_gen[0]  # 첫 번째 배치 가져오기\n",
    "print(x.shape, y.shape)\n",
    "print(np.min(x), np.max(x), np.min(y), np.max(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2e90fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 802816}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f98db0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = 1.0 / np.array(counts)\n",
    "class_weights = class_weights / np.sum(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cross_entropy(class_weights): \n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.nn.softmax(y_pred)  # softmax 활성화 함수 적용\n",
    "        loss_per_class = -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-5), axis=[1, 2])  # 상수를 1e-5로 변경\n",
    "        weighted_loss = loss_per_class * class_weights\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa184ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = weighted_cross_entropy(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca795ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(block_input, num_filters=256, kernel_size=3, \n",
    "                     dilation_rate=1, padding='same', use_bias=False):\n",
    "    x = layers.Conv2D(num_filters, kernel_size=kernel_size, \n",
    "                      dilation_rate=dilation_rate, padding='same', \n",
    "                      use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal())(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b432b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(size=(dims[-3]// x.shape[1], dims[-2]// x.shape[2]),\n",
    "                                         interpolation='bilinear')(x)\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    \n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7194fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeeplabV3(img_size, num_classes):\n",
    "    model_input = keras.Input(shape=img_size + (3,))\n",
    "    resnet50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "    \n",
    "    x = resnet50.get_layer('conv4_block6_2_relu').output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "    \n",
    "    input_a = layers.UpSampling2D(size=(img_size[0] // 4 // x.shape[1],\n",
    "                                       img_size[1] // 4 // x.shape[2]),\n",
    "                                       interpolation='bilinear')(x)\n",
    "    input_b = resnet50.get_layer('conv2_block3_2_relu').output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(size=(img_size[0] // x.shape[1],\n",
    "                                 img_size[1] // x.shape[2]),\n",
    "                           interpolation='bilinear')(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1,1), padding='same')(x)\n",
    "    \n",
    "    return keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d526733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3(img_size=img_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "337/337 [==============================] - ETA: 0s - loss: 844.0404 - accuracy: 0.1562"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6), loss=loss_function, metrics=['accuracy'])\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
