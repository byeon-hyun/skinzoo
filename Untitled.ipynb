{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86d16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow import keras\n",
    "from PIL import ImageFile\n",
    "import ast\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7b029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "num_classes = 6\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66de4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_polygon(size, polygon_string):\n",
    "    # Convert string to dictionary format\n",
    "    polygon_string = polygon_string.replace(\"'\", '\"')  # Convert single quotes to double quotes\n",
    "    polygon_string = \"{\" + polygon_string + \"}\"  # Add curly braces\n",
    "    # Parse the string to get a dictionary of coordinates\n",
    "    coords = ast.literal_eval(polygon_string)\n",
    "    # Convert dictionary to list of tuples (coordinates)\n",
    "    coords_list = [(v,k) for k,v in coords.items()]\n",
    "    # Create an empty mask\n",
    "    mask = np.zeros(size, dtype=np.uint8)\n",
    "    # Fill in the polygon\n",
    "    cv2.fillPoly(mask, np.int32([coords_list]), 1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ace9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_mask(path, polygon_string):\n",
    "    # Load the image\n",
    "    img = cv2.imread(path)\n",
    "    # Resize image if you want or convert to desired format\n",
    "    img = cv2.resize(img, (256, 256))  # Resize to your preferred size\n",
    "    img = img / 255.  # Scale to 0-1 if you prefer\n",
    "    # Create the mask from the polygon\n",
    "    mask = create_mask_from_polygon((img.shape[0], img.shape[1]), polygon_string)\n",
    "    # Reshape the mask to be compatible with image shape\n",
    "    mask = np.reshape(mask, (img.shape[0], img.shape[1], 1))\n",
    "    # Apply the mask to the image\n",
    "    img = img * mask\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e20229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDiseaseDataset(keras.utils.Sequence):\n",
    "    def __init__(self, df, img_size, img_dir, batch_size):\n",
    "        self.df = df\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.df[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype='float32')\n",
    "        y = np.zeros((self.batch_size, num_classes), dtype='float32')\n",
    "        for i, (index, row) in enumerate(batch.iterrows()):\n",
    "            path = os.path.join(self.img_dir, row['Raw data ID'])\n",
    "            img = load_image_and_mask(path, row['polygon_location'])\n",
    "            x[i] = img_to_array(img)\n",
    "            y[i, row['lesions']] = 1  # One-hot encoding\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c08d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_image2\"\n",
    "val_img_dir = \"C:/Users/oceanlightai/Desktop/datasets/pet_skin/validation/validation_image2\"\n",
    "\n",
    "# Load labels from CSV file\n",
    "train_df = pd.read_csv('C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_skin.csv')\n",
    "train_df['lesions'] = train_df['lesions'].astype('category').cat.codes\n",
    "\n",
    "val_df = pd.read_csv('C:/Users/oceanlightai/Desktop/datasets/pet_skin/valid/valid_skin.csv')\n",
    "val_df['lesions'] = val_df['lesions'].astype('category').cat.codes\n",
    "\n",
    "# Create generators\n",
    "train_gen = SkinDiseaseDataset(train_df, img_size, train_img_dir, batch_size)\n",
    "val_gen = SkinDiseaseDataset(val_df, img_size, val_img_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74268c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
    "x = Flatten()(base_model.output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46cda61",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\AppData\\Local\\Temp\\ipykernel_21064\\4067052162.py\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\"\u001b[0m, line \u001b[0;32m1147\u001b[0m, in \u001b[0;35mfit\u001b[0m\n    steps_per_execution=self._steps_per_execution)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\"\u001b[0m, line \u001b[0;32m1364\u001b[0m, in \u001b[0;35mget_data_handler\u001b[0m\n    return DataHandler(*args, **kwargs)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\"\u001b[0m, line \u001b[0;32m1166\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    model=model)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\"\u001b[0m, line \u001b[0;32m939\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    **kwargs)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\"\u001b[0m, line \u001b[0;32m809\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    peek, x = self._peek_and_restore(x)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\"\u001b[0m, line \u001b[0;32m943\u001b[0m, in \u001b[0;35m_peek_and_restore\u001b[0m\n    return x[0], x\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\AppData\\Local\\Temp\\ipykernel_21064\\1243461261.py\"\u001b[0m, line \u001b[0;32m17\u001b[0m, in \u001b[0;35m__getitem__\u001b[0m\n    img = load_image_and_mask(path, row['polygon_location'])\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\AppData\\Local\\Temp\\ipykernel_21064\\3884457019.py\"\u001b[0m, line \u001b[0;32m8\u001b[0m, in \u001b[0;35mload_image_and_mask\u001b[0m\n    mask = create_mask_from_polygon((img.shape[0], img.shape[1]), polygon_string)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\AppData\\Local\\Temp\\ipykernel_21064\\3647904612.py\"\u001b[0m, line \u001b[0;32m6\u001b[0m, in \u001b[0;35mcreate_mask_from_polygon\u001b[0m\n    coords = ast.literal_eval(polygon_string)\n",
      "  File \u001b[0;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\ast.py\"\u001b[0m, line \u001b[0;32m46\u001b[0m, in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\oceanlightai\\anaconda3\\envs\\gpu\\lib\\ast.py\"\u001b[1;36m, line \u001b[1;32m35\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<unknown>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    {x1\": 1140, \"y1\": 379, \"x2\": 1125, \"y2\": 370, \"x3\": 1107, \"y3\": 377, \"x4\": 1097, \"y4\": 388, \"x5\": 1081, \"y5\": 409, \"x6\": 1065, \"y6\": 439, \"x7\": 1060, \"y7\": 481, \"x8\": 1059, \"y8\": 506, \"x9\": 1061, \"y9\": 533, \"x10\": 1049, \"y10\": 563, \"x11\": 1062, \"y11\": 597, \"x12\": 1061, \"y12\": 624, \"x13\": 1068, \"y13\": 631, \"x14\": 1097, \"y14\": 605, \"x15\": 1129, \"y15\": 555, \"x16\": 1156, \"y16\": 527, \"x17\": 1164, \"y17\": 522, \"x18\": 1167, \"y18\": 520, \"x19\": 1177, \"y19\": 523, \"x20\": 1188, \"y20\": 530, \"x21\": 1195, \"y21\": 537, \"x22\": 1207, \"y22\": 550, \"x23\": 1216, \"y23\": 564, \"x24\": 1218, \"y24\": 572, \"x25\": 1216, \"y25\": 584, \"x26\": 1209, \"y26\": 603, \"x27\": 1179, \"y27\": 640, \"x28\": 1177, \"y28\": 645, \"x29\": 1151, \"y29\": 670, \"x30\": 1141, \"y30\": 687, \"x31\": 1140, \"y31\": 697, \"x32\": 1148, \"y32\": 703, \"x33\": 1158, \"y33\": 705, \"x34\": 1174, \"y34\": 707, \"x35\": 1192, \"y35\": 700, \"x36\": 1225, \"y36\": 683, \"x37\": 1256, \"y37\": 662, \"x38\": 1274, \"y38\": 635, \"x39\": 1275, \"y39\": 580, \"x40\": 1276, \"y40\": 536, \"x41\": 1272, \"y41\": 482, \"x42\": 1261, \"y42\": 454, \"x43\": 1255, \"y43\": 438, \"x44\": 1237, \"y44\": 413, \"x45\": 1225, \"y45\": 399, \"x46\": 1188, \"y46\": 379, \"x47\": 1167, \"y47\": 372, \"x48\": 1143, \"y48\": 364, \"x49\": 1140, \"y49\": 379}\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, validation_data=val_gen, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
