{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355280e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "# specify the directory where images are stored\n",
    "img_dir = r'C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_image'\n",
    "# specify the directory of the csv file\n",
    "csv_file = r'C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train_skin.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafe83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to convert different types of data into tf.train.Feature\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def create_tf_example(img_path, annotation):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_encoded = cv2.imencode('.jpg', img)[1].tostring()\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/encoded': _bytes_feature(img_encoded),\n",
    "        'image/object/bbox/xmin': _float_feature(annotation['x']),\n",
    "        'image/object/bbox/xmax': _float_feature(annotation['x'] + annotation['width']),\n",
    "        'image/object/bbox/ymin': _float_feature(annotation['y']),\n",
    "        'image/object/bbox/ymax': _float_feature(annotation['y'] + annotation['height']),\n",
    "        'image/object/class/label': _int64_feature(annotation['class_id']),\n",
    "    }))\n",
    "\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Get unique class names and create a mapping from class names to integer IDs\n",
    "unique_classes = df['lesions'].unique()\n",
    "class_dict = {name: idx for idx, name in enumerate(unique_classes)}\n",
    "\n",
    "# Path where the diseases.names and TFRecord files will be saved\n",
    "save_path = r'C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/tfrecod'\n",
    "\n",
    "# Write the class names to a text file\n",
    "with open(os.path.join(save_path, 'diseases.names'), 'w') as f:\n",
    "    for disease in unique_classes:\n",
    "        f.write(disease + '\\n')\n",
    "\n",
    "# Create TFRecords\n",
    "with tf.io.TFRecordWriter(os.path.join(save_path, 'train.tfrecord')) as writer:\n",
    "    for img_id, group in df.groupby('Raw data ID'):\n",
    "        img_path = os.path.join(img_dir, img_id)\n",
    "        for _, row in group.iterrows():\n",
    "            annotation = {\n",
    "                'x': row['x'] / 1920,\n",
    "                'y': row['y'] / 1080,\n",
    "                'width': row['width'] / 1920,\n",
    "                'height': row['height'] / 1080,\n",
    "                'class_id': class_dict[row['lesions']]\n",
    "            }\n",
    "            tf_example = create_tf_example(img_path, annotation)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the project\n",
    "!git clone https://github.com/zzh8829/yolov3-tf2.git\n",
    "%cd yolov3-tf2\n",
    "\n",
    "# Install requirements\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Prepare the configuration file\n",
    "with open('C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/tfrecod/diseases.names', 'w') as f:\n",
    "    for disease in unique_classes:\n",
    "        f.write(disease + '\\n')\n",
    "\n",
    "# Convert darknet weights to tensorflow model\n",
    "!python convert.py --weights ./data/yolov3.weights --output ./checkpoints/yolov3.tf\n",
    "\n",
    "# Train model\n",
    "!python train.py \\\n",
    "  --dataset C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/train.tfrecord \\\n",
    "  --classes C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/diseases.names \\\n",
    "  --num_classes len(unique_classes) \\\n",
    "  --mode fit --transfer darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"yolo_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6db3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights ./checkpoints/yolov3.tf \\\n",
    "  --classes C:/Users/oceanlightai/Desktop/datasets/pet_skin/train/diseases.names \\\n",
    "  --image C:/Users/oceanlightai/Desktop/datasets/pet_skin/valid/IMG_D_A1_011078.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
